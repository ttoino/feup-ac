{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/main_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})\n",
    "df.drop(['current_year_rank'], axis=1, inplace=True)\n",
    "\n",
    "def process_categorical(df, col):\n",
    "    \"\"\"\n",
    "    Processes a column of *df* as categorical\n",
    "    \"\"\"\n",
    "\n",
    "    def mapping(df, col):\n",
    "\n",
    "        new_df = df.copy()\n",
    "\n",
    "        values = new_df[col].unique()\n",
    "        mapping = {value: i for i, value in enumerate(values)}\n",
    "        new_df[col] = new_df[col].map(mapping)\n",
    "\n",
    "        return new_df\n",
    "\n",
    "    def one_hot(df, col):\n",
    "        ext_df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "        ext_df.drop([col], axis=1, inplace=True)\n",
    "        \n",
    "        return ext_df\n",
    "\n",
    "    return mapping(df, col)\n",
    "\n",
    "df = process_categorical(df, \"tmID\")\n",
    "# map_strings_to_int(df, \"playerID\")\n",
    "# map_strings_to_int(df, \"coachID\")\n",
    "# map_strings_to_int(df, \"pos\")\n",
    "\n",
    "df.to_csv(\"../data/clean/pre.csv\", index=False)\n",
    "\n",
    "# print(df['tmID'].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn string values into numerical ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    year: int\n",
    "    accuracy: float\n",
    "    auc: float\n",
    "\n",
    "results = {}\n",
    "\n",
    "def classification(model, df, min_year, max_year, param_list):\n",
    "\n",
    "    def cv(df, min_year, max_year):\n",
    "        for i in range(min_year, max_year + 1):\n",
    "            df_train = df[(df['year'] < i) & (df['year'] > 1)]\n",
    "            df_test = df[df['year'] == i]\n",
    "\n",
    "            X_train = df_train.drop(\"playoff\", axis=1)  # Features\n",
    "            y_train = df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "            X_test = df_test.drop(\"playoff\", axis=1)  # Features\n",
    "            y_test = df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "\n",
    "    def score(model, df, min_year, max_year):\n",
    "        results = []\n",
    "        \n",
    "        for i in range(min_year, max_year + 1):\n",
    "            df_train = df[(df['year'] < i) & (df['year'] > 1)]\n",
    "            df_test = df[df['year'] == i]\n",
    "\n",
    "            X_train = df_train.drop(\"playoff\", axis=1)  # Features\n",
    "            y_train = df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "            X_test = df_test.drop(\"playoff\", axis=1)  # Features\n",
    "            y_test = df_test[\"playoff\"]  # Target variable\n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            results.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "        return sum(result * (i + 1) for result, i in enumerate(results)) / sum(range(len(results) + 1))\n",
    "\n",
    "    def param_tuning(model, df, min_year, max_year, param_list):\n",
    "        grid = HalvingGridSearchCV(model, param_grid=param_list, cv=5, n_jobs=16, scoring=lambda model, X, y: score(model, df, min_year, max_year))\n",
    "        grid.fit(df.drop(\"playoff\", axis=1), df[\"playoff\"])\n",
    "        \n",
    "        return grid.best_estimator_\n",
    "    \n",
    "    def test_model(model, df, params):\n",
    "        pass\n",
    "\n",
    "    model = param_tuning(model, df, min_year, max_year, param_list)\n",
    "\n",
    "    for i in range(min_year, max_year + 1):\n",
    "        df_train = df[(df['year'] < i) & (df['year'] > 1)]\n",
    "        df_test = df[df['year'] == i]\n",
    "\n",
    "        X_train = df_train.drop(\"playoff\", axis=1)  # Features\n",
    "        y_train = df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "        X_test = df_test.drop(\"playoff\", axis=1)  # Features\n",
    "        y_test = df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "        print(f\"\\nTrain/Test size for year={i}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the response for the test dataset\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"\\nyear = {i}, Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "        print(f\"\\nyear = {i}, Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(f\"\\nyear = {i}, AUC: \", roc_auc_score(y_test, y_pred))\n",
    "        print(f\"\\nyear = {i}, Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "        result = Result(\n",
    "            year=i,\n",
    "            accuracy=accuracy_score(y_test, y_pred),\n",
    "            auc=roc_auc_score(y_test, y_pred),\n",
    "        )\n",
    "\n",
    "        if (str(model) not in results):\n",
    "            results[str(model)] = []\n",
    "        results[str(model)].append(result)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define values for min_year and max_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = 3\n",
    "max_year = df['year'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model = classification(model, df, min_year, max_year, param_list={\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': range(2, 20),\n",
    "})\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(model, filled=True, feature_names=df.columns.to_list(), rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(random_state=42)\n",
    "classification(model, df, min_year, max_year, param_list={\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': range(1, 10),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C': range(1, 10),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "classification(model, df, min_year, max_year, param_list={\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': range(1, 10),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [1000],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "classification(model, df, min_year, max_year, {\n",
    "    'n_estimators': range(1, 10),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 10),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "classification(model, df, min_year, max_year, {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.1, 0.5, 1],\n",
    "    'n_estimators': range(1, 10),\n",
    "    'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "    'max_depth': range(1, 10),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "classification(model, df, min_year, max_year, param_list={\n",
    "    'n_neighbors': range(1, 10),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': range(1, 10),\n",
    "    'p': [1, 2],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Extracting accuracy for the last year for each model\n",
    "previous_year_accuracies = {model: results[model][-1].accuracy for model in results}\n",
    "\n",
    "# Sorting the results by accuracy in descending order\n",
    "sorted_results = dict(sorted(previous_year_accuracies.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Printing the results\n",
    "print(\"Train/test results for the last year of data:\\n\")\n",
    "for model, accuracy in sorted_results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "\n",
    "for model in results:\n",
    "    for result in results[model]:\n",
    "        if result.accuracy == 1:\n",
    "            print(f\"\\n{model} has 100% accuracy for year {result.year}, possible data leakage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
