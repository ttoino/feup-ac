{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary/unfit columns\n",
    "teams_df = df.drop([\"rank\", \"seeded\", \"lgID\", \"tmID\", \"franchID\", \"confID\", \"divID\", \"name\", \"arena\", \"firstRound\", \"semis\", \"finals\"], axis=1)\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "teams_df[\"playoff\"] = teams_df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    year: int\n",
    "    accuracy: float\n",
    "    auc: float\n",
    "\n",
    "results = {}\n",
    "\n",
    "def classification(model, teams_df, min_year, max_year):\n",
    "    for i in range(min_year, max_year + 1):\n",
    "        teams_df_train = teams_df[teams_df['year'] < i]\n",
    "        teams_df_test = teams_df[teams_df['year'] == i]\n",
    "\n",
    "        X_train = teams_df_train.drop(\"playoff\", axis=1)  # Features\n",
    "        y_train = teams_df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "        X_test = teams_df_test.drop(\"playoff\", axis=1)  # Features\n",
    "        y_test = teams_df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "        print(f\"\\nTrain/Test size for year={i}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the response for the test dataset\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"\\nyear = {i}, Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(f\"\\nyear = {i}, Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(f\"\\nyear = {i}, AUC: \", roc_auc_score(y_test, y_pred))\n",
    "        print(f\"\\nyear = {i}, Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "        result = Result(\n",
    "            year=i,\n",
    "            accuracy=accuracy_score(y_test, y_pred),\n",
    "            auc=roc_auc_score(y_test, y_pred),\n",
    "        )\n",
    "\n",
    "        if (str(model) not in results):\n",
    "            results[str(model)] = []\n",
    "        results[str(model)].append(result)\n",
    "\n",
    "min_year = 2\n",
    "max_year = teams_df['year'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         8\n",
      "           1       0.50      0.75      0.60         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.50      0.50      0.47        16\n",
      "weighted avg       0.50      0.50      0.47        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[2 6]\n",
      " [2 6]]\n",
      "\n",
      "year = 2, AUC:  0.5\n",
      "\n",
      "year = 2, Accuracy:  0.5\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.81      0.81        16\n",
      "weighted avg       0.82      0.81      0.81        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[6 2]\n",
      " [1 7]]\n",
      "\n",
      "year = 3, AUC:  0.8125\n",
      "\n",
      "year = 3, Accuracy:  0.8125\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         6\n",
      "           1       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.83      0.81      0.78        14\n",
      "weighted avg       0.86      0.79      0.78        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[6 0]\n",
      " [3 5]]\n",
      "\n",
      "year = 4, AUC:  0.8125\n",
      "\n",
      "year = 4, Accuracy:  0.7857142857142857\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.92        13\n",
      "   macro avg       0.92      0.94      0.92        13\n",
      "weighted avg       0.94      0.92      0.92        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[5 0]\n",
      " [1 7]]\n",
      "\n",
      "year = 5, AUC:  0.9375\n",
      "\n",
      "year = 5, Accuracy:  0.9230769230769231\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[5 0]\n",
      " [0 8]]\n",
      "\n",
      "year = 6, AUC:  1.0\n",
      "\n",
      "year = 6, Accuracy:  1.0\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.85      0.85      0.85        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[5 1]\n",
      " [1 7]]\n",
      "\n",
      "year = 7, AUC:  0.8541666666666666\n",
      "\n",
      "year = 7, Accuracy:  0.8571428571428571\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.81      0.81      0.77        13\n",
      "weighted avg       0.86      0.77      0.77        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[5 0]\n",
      " [3 5]]\n",
      "\n",
      "year = 8, AUC:  0.8125\n",
      "\n",
      "year = 8, Accuracy:  0.7692307692307693\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.79      0.77      0.78        14\n",
      "weighted avg       0.79      0.79      0.78        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[4 2]\n",
      " [1 7]]\n",
      "\n",
      "year = 9, AUC:  0.7708333333333335\n",
      "\n",
      "year = 9, Accuracy:  0.7857142857142857\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71         5\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.78      0.75      0.69        13\n",
      "weighted avg       0.83      0.69      0.68        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[5 0]\n",
      " [4 4]]\n",
      "\n",
      "year = 10, AUC:  0.75\n",
      "\n",
      "year = 10, Accuracy:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "classification(model, teams_df, min_year, max_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67         8\n",
      "           1       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.60      0.56      0.52        16\n",
      "weighted avg       0.60      0.56      0.52        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[7 1]\n",
      " [6 2]]\n",
      "\n",
      "year = 2, AUC:  0.5625\n",
      "\n",
      "year = 2, Accuracy:  0.5625\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         8\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.83      0.75      0.73        16\n",
      "weighted avg       0.83      0.75      0.73        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[8 0]\n",
      " [4 4]]\n",
      "\n",
      "year = 3, AUC:  0.75\n",
      "\n",
      "year = 3, Accuracy:  0.75\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.14      0.25      0.18        14\n",
      "weighted avg       0.12      0.21      0.15        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[3 3]\n",
      " [8 0]]\n",
      "\n",
      "year = 4, AUC:  0.25\n",
      "\n",
      "year = 4, Accuracy:  0.21428571428571427\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71         5\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.78      0.75      0.69        13\n",
      "weighted avg       0.83      0.69      0.68        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[5 0]\n",
      " [4 4]]\n",
      "\n",
      "year = 5, AUC:  0.75\n",
      "\n",
      "year = 5, Accuracy:  0.6923076923076923\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.70      0.88      0.78         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.68      0.64      0.64        13\n",
      "weighted avg       0.69      0.69      0.67        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[2 3]\n",
      " [1 7]]\n",
      "\n",
      "year = 6, AUC:  0.6375\n",
      "\n",
      "year = 6, Accuracy:  0.6923076923076923\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29         6\n",
      "           1       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.81      0.58      0.52        14\n",
      "weighted avg       0.78      0.64      0.56        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[1 5]\n",
      " [0 8]]\n",
      "\n",
      "year = 7, AUC:  0.5833333333333333\n",
      "\n",
      "year = 7, Accuracy:  0.6428571428571429\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.83      0.60      0.57        13\n",
      "weighted avg       0.79      0.69      0.62        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[1 4]\n",
      " [0 8]]\n",
      "\n",
      "year = 8, AUC:  0.6\n",
      "\n",
      "year = 8, Accuracy:  0.6923076923076923\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29         6\n",
      "           1       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.81      0.58      0.52        14\n",
      "weighted avg       0.78      0.64      0.56        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[1 5]\n",
      " [0 8]]\n",
      "\n",
      "year = 9, AUC:  0.5833333333333333\n",
      "\n",
      "year = 9, Accuracy:  0.6428571428571429\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.83      0.60      0.57        13\n",
      "weighted avg       0.79      0.69      0.62        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[1 4]\n",
      " [0 8]]\n",
      "\n",
      "year = 10, AUC:  0.6\n",
      "\n",
      "year = 10, Accuracy:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42)\n",
    "classification(model, teams_df, min_year, max_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         8\n",
      "           1       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.90      0.88      0.87        16\n",
      "weighted avg       0.90      0.88      0.87        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[6 2]\n",
      " [0 8]]\n",
      "\n",
      "year = 2, AUC:  0.875\n",
      "\n",
      "year = 2, Accuracy:  0.875\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.81      0.81        16\n",
      "weighted avg       0.82      0.81      0.81        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[6 2]\n",
      " [1 7]]\n",
      "\n",
      "year = 3, AUC:  0.8125\n",
      "\n",
      "year = 3, Accuracy:  0.8125\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.83      0.62         6\n",
      "           1       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.62      0.60      0.56        14\n",
      "weighted avg       0.64      0.57      0.55        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[5 1]\n",
      " [5 3]]\n",
      "\n",
      "year = 4, AUC:  0.6041666666666667\n",
      "\n",
      "year = 4, Accuracy:  0.5714285714285714\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73         5\n",
      "           1       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.76      0.78      0.76        13\n",
      "weighted avg       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[4 1]\n",
      " [2 6]]\n",
      "\n",
      "year = 5, AUC:  0.7750000000000001\n",
      "\n",
      "year = 5, Accuracy:  0.7692307692307693\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.70      0.71      0.69        13\n",
      "weighted avg       0.73      0.69      0.70        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[4 1]\n",
      " [3 5]]\n",
      "\n",
      "year = 6, AUC:  0.7125\n",
      "\n",
      "year = 6, Accuracy:  0.6923076923076923\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.88      0.88      0.86        14\n",
      "weighted avg       0.89      0.86      0.86        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[6 0]\n",
      " [2 6]]\n",
      "\n",
      "year = 7, AUC:  0.875\n",
      "\n",
      "year = 7, Accuracy:  0.8571428571428571\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62         5\n",
      "           1       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.73      0.62      0.51        13\n",
      "weighted avg       0.79      0.54      0.49        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[5 0]\n",
      " [6 2]]\n",
      "\n",
      "year = 8, AUC:  0.625\n",
      "\n",
      "year = 8, Accuracy:  0.5384615384615384\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.94      0.92      0.93        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[5 1]\n",
      " [0 8]]\n",
      "\n",
      "year = 9, AUC:  0.9166666666666667\n",
      "\n",
      "year = 9, Accuracy:  0.9285714285714286\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/naapperas/.local/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83         5\n",
      "           1       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.86      0.88      0.85        13\n",
      "weighted avg       0.89      0.85      0.85        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[5 0]\n",
      " [2 6]]\n",
      "\n",
      "year = 10, AUC:  0.875\n",
      "\n",
      "year = 10, Accuracy:  0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, max_iter=100000, solver='newton-cg')\n",
    "classification(model, teams_df, min_year, max_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.88      0.88      0.88        16\n",
      "weighted avg       0.88      0.88      0.88        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[7 1]\n",
      " [1 7]]\n",
      "\n",
      "year = 2, AUC:  0.875\n",
      "\n",
      "year = 2, Accuracy:  0.875\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.94      0.94      0.94        16\n",
      "weighted avg       0.94      0.94      0.94        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[7 1]\n",
      " [0 8]]\n",
      "\n",
      "year = 3, AUC:  0.9375\n",
      "\n",
      "year = 3, Accuracy:  0.9375\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.79      0.79      0.78        14\n",
      "weighted avg       0.80      0.79      0.79        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[5 1]\n",
      " [2 6]]\n",
      "\n",
      "year = 4, AUC:  0.7916666666666667\n",
      "\n",
      "year = 4, Accuracy:  0.7857142857142857\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.92        13\n",
      "   macro avg       0.92      0.94      0.92        13\n",
      "weighted avg       0.94      0.92      0.92        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[5 0]\n",
      " [1 7]]\n",
      "\n",
      "year = 5, AUC:  0.9375\n",
      "\n",
      "year = 5, Accuracy:  0.9230769230769231\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.92        13\n",
      "   macro avg       0.92      0.94      0.92        13\n",
      "weighted avg       0.94      0.92      0.92        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[5 0]\n",
      " [1 7]]\n",
      "\n",
      "year = 6, AUC:  0.9375\n",
      "\n",
      "year = 6, Accuracy:  0.9230769230769231\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.94      0.92      0.93        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[5 1]\n",
      " [0 8]]\n",
      "\n",
      "year = 7, AUC:  0.9166666666666667\n",
      "\n",
      "year = 7, Accuracy:  0.9285714285714286\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.92        13\n",
      "   macro avg       0.92      0.94      0.92        13\n",
      "weighted avg       0.94      0.92      0.92        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[5 0]\n",
      " [1 7]]\n",
      "\n",
      "year = 8, AUC:  0.9375\n",
      "\n",
      "year = 8, Accuracy:  0.9230769230769231\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.94      0.92      0.93        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[5 1]\n",
      " [0 8]]\n",
      "\n",
      "year = 9, AUC:  0.9166666666666667\n",
      "\n",
      "year = 9, Accuracy:  0.9285714285714286\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.81      0.81      0.77        13\n",
      "weighted avg       0.86      0.77      0.77        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[5 0]\n",
      " [3 5]]\n",
      "\n",
      "year = 10, AUC:  0.8125\n",
      "\n",
      "year = 10, Accuracy:  0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "classification(model, teams_df, min_year, max_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67         8\n",
      "           1       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.60      0.56      0.52        16\n",
      "weighted avg       0.60      0.56      0.52        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[7 1]\n",
      " [6 2]]\n",
      "\n",
      "year = 2, AUC:  0.5625\n",
      "\n",
      "year = 2, Accuracy:  0.5625\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         8\n",
      "           1       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.63      0.62      0.62        16\n",
      "weighted avg       0.63      0.62      0.62        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[6 2]\n",
      " [4 4]]\n",
      "\n",
      "year = 3, AUC:  0.625\n",
      "\n",
      "year = 3, Accuracy:  0.625\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46         6\n",
      "           1       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.50      0.50      0.50        14\n",
      "weighted avg       0.51      0.50      0.50        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[3 3]\n",
      " [4 4]]\n",
      "\n",
      "year = 4, AUC:  0.5\n",
      "\n",
      "year = 4, Accuracy:  0.5\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.92        13\n",
      "   macro avg       0.92      0.94      0.92        13\n",
      "weighted avg       0.94      0.92      0.92        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[5 0]\n",
      " [1 7]]\n",
      "\n",
      "year = 5, AUC:  0.9375\n",
      "\n",
      "year = 5, Accuracy:  0.9230769230769231\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.20      0.20         5\n",
      "           1       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.38        13\n",
      "   macro avg       0.35      0.35      0.35        13\n",
      "weighted avg       0.38      0.38      0.38        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[1 4]\n",
      " [4 4]]\n",
      "\n",
      "year = 6, AUC:  0.35\n",
      "\n",
      "year = 6, Accuracy:  0.38461538461538464\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.17      0.20         6\n",
      "           1       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.38      0.40      0.38        14\n",
      "weighted avg       0.39      0.43      0.40        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[1 5]\n",
      " [3 5]]\n",
      "\n",
      "year = 7, AUC:  0.3958333333333333\n",
      "\n",
      "year = 7, Accuracy:  0.42857142857142855\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.40      0.36         5\n",
      "           1       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.45      0.45      0.45        13\n",
      "weighted avg       0.48      0.46      0.47        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[2 3]\n",
      " [4 4]]\n",
      "\n",
      "year = 8, AUC:  0.45000000000000007\n",
      "\n",
      "year = 8, Accuracy:  0.46153846153846156\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22         6\n",
      "           1       0.55      0.75      0.63         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.44      0.46      0.43        14\n",
      "weighted avg       0.45      0.50      0.46        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[1 5]\n",
      " [2 6]]\n",
      "\n",
      "year = 9, AUC:  0.4583333333333333\n",
      "\n",
      "year = 9, Accuracy:  0.5\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.68      0.68      0.68        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[3 2]\n",
      " [2 6]]\n",
      "\n",
      "year = 10, AUC:  0.675\n",
      "\n",
      "year = 10, Accuracy:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "classification(model, teams_df, min_year, max_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTreeClassifier(random_state=42)': 0.6923076923076923,\n",
      " 'KNeighborsClassifier()': 0.6923076923076923,\n",
      " \"LogisticRegression(max_iter=100000, random_state=42, solver='newton-cg')\": 0.8461538461538461,\n",
      " 'RandomForestClassifier(random_state=42)': 0.7692307692307693,\n",
      " 'SVC(random_state=42)': 0.6923076923076923}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# This is ugly\n",
    "pprint(dict(sorted(dict(map(lambda i: (i[0], i[1].accuracy), dict(map(lambda i: (i[0], i[1][-1]), results.items())).items())).items(), key=lambda i: i[1], reverse=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
